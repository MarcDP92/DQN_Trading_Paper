# DQN_Trading_Paper
### Abstract
Reinforcement learning has been a widely explored technique to create agents that respond optimally in a
time-series environment. This paper has been created to explore the limits of this technique using
real-world data for a time series in the crypto-market. Xiang Gao in his paper Deep reinforcement learning
for time series: playing idealized trading games [1], used Deep Q-learning to create an optimal policy for
an agent with made-up procedural data and its results are promising. So it has been used as a
benchmark to compare with similar architectures but using real data from the BTC/USDT pair in the
cryptomarket. The results of the experiment show that using the same approach as X. Gao, but with real
data ended up with 66.6% success using a MLP architecture.
